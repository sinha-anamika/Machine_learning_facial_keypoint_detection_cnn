{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Net3 model: Training individual facial features as models\n",
    "## Loading pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from pandas.io.parsers import read_csv\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data and load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_eye_center_x            7039\n",
      "left_eye_center_y            7039\n",
      "right_eye_center_x           7036\n",
      "right_eye_center_y           7036\n",
      "left_eye_inner_corner_x      2271\n",
      "left_eye_inner_corner_y      2271\n",
      "left_eye_outer_corner_x      2267\n",
      "left_eye_outer_corner_y      2267\n",
      "right_eye_inner_corner_x     2268\n",
      "right_eye_inner_corner_y     2268\n",
      "right_eye_outer_corner_x     2268\n",
      "right_eye_outer_corner_y     2268\n",
      "left_eyebrow_inner_end_x     2270\n",
      "left_eyebrow_inner_end_y     2270\n",
      "left_eyebrow_outer_end_x     2225\n",
      "left_eyebrow_outer_end_y     2225\n",
      "right_eyebrow_inner_end_x    2270\n",
      "right_eyebrow_inner_end_y    2270\n",
      "right_eyebrow_outer_end_x    2236\n",
      "right_eyebrow_outer_end_y    2236\n",
      "nose_tip_x                   7049\n",
      "nose_tip_y                   7049\n",
      "mouth_left_corner_x          2269\n",
      "mouth_left_corner_y          2269\n",
      "mouth_right_corner_x         2270\n",
      "mouth_right_corner_y         2270\n",
      "mouth_center_top_lip_x       2275\n",
      "mouth_center_top_lip_y       2275\n",
      "mouth_center_bottom_lip_x    7016\n",
      "mouth_center_bottom_lip_y    7016\n",
      "Image                        7049\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "FROOT = os.getcwd() \n",
    "FTRAIN = FROOT + '/data/training.csv'\n",
    "FTEST = FROOT + '/data/test.csv'\n",
    "\n",
    "def load(test = False, cols = None):\n",
    "    \"\"\"\n",
    "    Loads the data. Gets training data by default. \n",
    "    cols = None gets all columns. \n",
    "    cols  is set to individual column names using the facial_group_col in facial_group_settings\n",
    "    function. This parameter is set only while training individual facial group models.\n",
    "    \n",
    "    Returns a tuple(X,y) for training, y has none for test.\n",
    "      \n",
    "    \"\"\"\n",
    "    \n",
    "    if test:\n",
    "        fname = FTEST \n",
    "    else: \n",
    "        fname =FTRAIN\n",
    "        \n",
    "    df = read_csv(os.path.expanduser(fname))  \n",
    "\n",
    "    # The Image column has pixel values separated by space; convert\n",
    "    # the values to numpy arrays:\n",
    "    df['Image'] = df['Image'].apply(lambda im: np.fromstring(im, sep = ' '))\n",
    "\n",
    "    if cols:  # get a subset of columns\n",
    "        df = df[list(cols) + ['Image']]\n",
    "\n",
    "    print(df.count())  # prints the number of values for each column\n",
    "    df = df.dropna()  # drop all rows that have missing values in them\n",
    "    \n",
    "    # Normalize pixel values to be within [0, 1]\n",
    "    X = np.vstack(df['Image'].values) / 255. \n",
    "    X = X.astype(np.float32)\n",
    "\n",
    "    if not test:  # only FTRAIN has any target columns\n",
    "        y = df[df.columns[:-1]].values\n",
    "        y = (y - 48) / 48  # scale target coordinates to [-1, 1]\n",
    "        \n",
    "        #shuffle train data\n",
    "        shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "        X, y = X[shuffle], y[shuffle]\n",
    "\n",
    "        \n",
    "        y = y.astype(np.float32)\n",
    "    else:\n",
    "        y = None\n",
    "\n",
    "    return X, y\n",
    "\n",
    "    \n",
    "X, y = load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_channels = 1 # grayscale\n",
    "image_size = 96\n",
    "#load2d reshapes the data to be used for convolutional layers\n",
    "def load2d(test = False, cols = None):\n",
    "    X, y = load(test = test, cols = cols)\n",
    "    X = X.reshape(-1, image_size, image_size, num_channels)\n",
    "    return X, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Individual model settings\n",
    "\n",
    "On examining the number of datapoints available for each feature, individual models are made by grouping similar features based on number of data points availabe. the main idea being to maximize use of data. Below is the reasoning behind combining different labels.\n",
    "\n",
    "1. First I considered putting all eye data into one model, but as we can see above that left_eye_center_x, left_eye_center_y, right_eye_center_x , right_eye_center_y have more than 7000 data points while the remining\n",
    "eye data points only have 2267 - 2271 data points. So eye data points have been split into two models namely eye center and eye corner.\n",
    "left_eye_center_x            7039\n",
    "left_eye_center_y            7039\n",
    "right_eye_center_x           7036\n",
    "right_eye_center_y           7036\n",
    "\n",
    "#### Facial_group_models - Thirty keypoints have been grouped in six types to create specialized models\n",
    "#### These specialized models are eye_center, eye_corners, nose_tip, mouth_corner_top, mouth_bottom and eyebrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Uncomment the dict to run a particular model\n",
    "facial_group_labels = [\n",
    "   \n",
    "    dict(\n",
    "        name = \"mouth_corner_top\",\n",
    "        columns = (\n",
    "            'mouth_left_corner_x', 'mouth_left_corner_y',\n",
    "            'mouth_right_corner_x', 'mouth_right_corner_y',\n",
    "            'mouth_center_top_lip_x', 'mouth_center_top_lip_y',\n",
    "            )),\n",
    "     \n",
    "#      dict(\n",
    "#          name = \"nose_tip\",\n",
    "#          columns = (\n",
    "#              'nose_tip_x', 'nose_tip_y',\n",
    "#              )),\n",
    "\n",
    "#     dict(\n",
    "#         name = \"mouth_bottom\",\n",
    "#         columns = (\n",
    "#             'mouth_center_bottom_lip_x',\n",
    "#             'mouth_center_bottom_lip_y',\n",
    "#             )),\n",
    "\n",
    "#     dict(\n",
    "#         name = \"eye_corner\",\n",
    "#         columns = (\n",
    "#             'left_eye_inner_corner_x', 'left_eye_inner_corner_y',\n",
    "#             'right_eye_inner_corner_x', 'right_eye_inner_corner_y',\n",
    "#             'left_eye_outer_corner_x', 'left_eye_outer_corner_y',\n",
    "#             'right_eye_outer_corner_x', 'right_eye_outer_corner_y',\n",
    "#             )),\n",
    "#\n",
    "    dict(\n",
    "        name = \"eyebrow\",\n",
    "        columns = (\n",
    "            'left_eyebrow_inner_end_x', 'left_eyebrow_inner_end_y',\n",
    "            'right_eyebrow_inner_end_x', 'right_eyebrow_inner_end_y',\n",
    "            'left_eyebrow_outer_end_x', 'left_eyebrow_outer_end_y',\n",
    "            'right_eyebrow_outer_end_x', 'right_eyebrow_outer_end_y',\n",
    "            )),\n",
    "    \n",
    "#      dict(\n",
    "#         name = \"eye_center\",\n",
    "#         columns = (\n",
    "#             'left_eye_center_x', 'left_eye_center_y',\n",
    "#             'right_eye_center_x', 'right_eye_center_y',\n",
    "#             )),\n",
    "    ]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating file path to store individual facial model data\n",
    "\n",
    "root_location = FROOT + \"/models/\"\n",
    "\n",
    "\n",
    "def model_name(facial_model_name):\n",
    "    return \"model_\" + facial_model_name\n",
    "\n",
    "def model_path(facial_model_name):\n",
    "    return root_location + \"ind_models/\" + model_name(facial_model_name) + \"/model.ckpt\"\n",
    "\n",
    "def train_history_path(facial_model_name):\n",
    "    return root_location + \"ind_models/\" + model_name(facial_model_name) + \"/train_history\"\n",
    "\n",
    "def create_directory_for_specialist(facial_model_name):\n",
    "    return os.makedirs(root_location + \"ind_models/\" + model_name(facial_model_name) + \"/\", exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_sample(x, y, axis):\n",
    "    \"\"\"\n",
    "    To visualize images with keypoints.\n",
    "    Note that it also takes in axis parameter   \n",
    "    \"\"\"\n",
    "    img = x.reshape(96, 96)\n",
    "    axis.imshow(img, cmap='gray')\n",
    "    axis.scatter(y[0::2] * 48 + 48, y[1::2] * 48 + 48, marker='x', s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining functions for different layers to be used in the network\n",
    "\n",
    "def fully_connected(input, nodes):\n",
    "    \n",
    "    # Creates a fully connected layer initializing Weight W with Xavier initializer \n",
    "    # and bias b with constant initializer\n",
    "    #Input is the 4 dimension and nodes is number of units in the fully connected layer.\n",
    "    \n",
    "    \n",
    "    weights = tf.get_variable( 'weights', shape = [input.get_shape()[1], nodes],\n",
    "        initializer = tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable( 'biases',shape = [nodes],initializer=tf.constant_initializer(0.0))\n",
    "    return tf.matmul(input, weights) + biases\n",
    "\n",
    "def fully_connected_relu(input, size):\n",
    "    #Creates a fully connected TensorFlow layer with ReLU activation applied.\n",
    "    return tf.nn.relu(fully_connected(input, size))\n",
    "\n",
    "def conv_relu(input, kernel_size, depth):\n",
    "    #Creates a convolutional TensorFlow layer and applies  ReLU activation function to it.\n",
    "    #Input is 4 dimensions\n",
    "    #\n",
    "    weights = tf.get_variable( 'weights', shape = [kernel_size, kernel_size, input.get_shape()[3], depth],\n",
    "        initializer = tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    biases = tf.get_variable( 'biases',shape = [depth],initializer=tf.constant_initializer(0.0))\n",
    "    conv = tf.nn.conv2d(input, weights,strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return tf.nn.relu(conv + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define our convolutional layers here.\n",
    "\n",
    "def conv_flow(input, keypoints, training):\n",
    "    \n",
    "    # Convolutional layers\n",
    "    with tf.variable_scope('conv1'):\n",
    "        #Input is (num of rows, 96, 96, 1)\n",
    "        conv1 = conv_relu(input, kernel_size = 3, depth = 32) \n",
    "        \n",
    "        #shape of conv1 should be ( num of rows, 96, 96,depth ofconv1)\n",
    "        pool1 =tf.nn.max_pool(conv1,ksize=[1,2,2,1], strides=[1,2,2,1],padding='SAME')\n",
    "        \n",
    "        \n",
    "        # Apply dropout if needed\n",
    "        \n",
    "        #tf.cond is a conditional check. If training is true, then apply keep_prob, else don't apply it.\n",
    "        pool1 = tf.cond(training, lambda: tf.nn.dropout(pool1, keep_prob = 0.9), lambda: pool1)\n",
    "    with tf.variable_scope('conv2'):\n",
    "        conv2 = conv_relu(pool1, kernel_size = 2, depth = 64)\n",
    "        \n",
    "        pool2 =tf.nn.max_pool(conv2,ksize=[1,2,2,1], strides=[1,2,2,1],padding='SAME')\n",
    "        \n",
    "        # Apply dropout if needed\n",
    "        pool2 = tf.cond(training, lambda: tf.nn.dropout(pool2, keep_prob = 0.8), lambda: pool2)\n",
    "    with tf.variable_scope('conv3'):\n",
    "        conv3 = conv_relu(pool2, kernel_size = 2, depth = 128)\n",
    "        pool3 =tf.nn.max_pool(conv3,ksize=[1,2,2,1], strides=[1,2,2,1],padding='SAME')\n",
    "        # Apply dropout if needed\n",
    "        pool3 = tf.cond(training, lambda: tf.nn.dropout(pool3, keep_prob = 0.7), lambda: pool3)\n",
    "    \n",
    "    # Flatten convolutional layers output\n",
    "    shape = pool3.get_shape().as_list()\n",
    "    flattened = tf.reshape(pool3, [-1, shape[1] * shape[2] * shape[3]])\n",
    "    \n",
    "    # Fully connected layers\n",
    "    with tf.variable_scope('fc4'):\n",
    "        fc4 = fully_connected_relu(flattened, 1000)\n",
    "        \n",
    "        # Apply dropout if needed\n",
    "        fc4 = tf.cond(training, lambda: tf.nn.dropout(fc4, keep_prob = 0.5), lambda: fc4)\n",
    "    with tf.variable_scope('fc5'):\n",
    "        #We have 1000 units in our fully connected layer\n",
    "        fc5 = fully_connected_relu(fc4, 1000)\n",
    "    with tf.variable_scope('out'):\n",
    "        #the output layer is just a fully connected layer with 30 nodes for the keypoints\n",
    "        prediction = fully_connected(fc5, keypoints)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "batch_size = 128\n",
    "every_epoch_to_log = 5\n",
    "\n",
    "def train_individual_model(facial_model_label):\n",
    "    \n",
    "            \n",
    "    # Load data for the group( groups are nose_tip, eye_center etc each with their own set of keypoints) \n",
    "    #and split into train, test & dev datasets\n",
    "    X, y = load2d(cols = facial_model_label['columns'])\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "    x_test, x_valid, y_test, y_valid = train_test_split(x_test, y_test, test_size = 0.5)    \n",
    "\n",
    "    # prepare the file paths\n",
    "    feature_name = facial_model_label['name']\n",
    "    create_directory_for_specialist(feature_name)\n",
    "    spec_var_scope = model_name(feature_name)\n",
    "    initialising_model = \"3con_2fc_b36_e9_aug_lrdec_mominc_dr\"\n",
    "\n",
    "    # Calculate some of the training hyperparameters based on the specialist and available data\n",
    "    \n",
    "    max_epochs = 5\n",
    "    num_keypoints = y.shape[1]\n",
    "    \n",
    "    # training time start\n",
    "    time_start = time.time()\n",
    "    \n",
    "    # Build the graph\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        # Input data. For the training data, we use a placeholder that will be fed at run time with a training minibatch.\n",
    "        tf_x_batch = tf.placeholder(tf.float32, shape = (None, image_size, image_size, num_channels))\n",
    "        tf_y_batch = tf.placeholder(tf.float32, shape = (None, num_keypoints))\n",
    "        is_training = tf.placeholder(tf.bool)\n",
    "        \n",
    "        current_epoch = tf.Variable(0)  # count the number of epochs\n",
    "\n",
    "        # learning rate decay. - Idea is to start with high learning rate to speed up but decrease as we get closer to \n",
    "        #the local optimum so that we don't surpass it.\n",
    "        learning_rate = tf.train.exponential_decay(0.03, current_epoch, decay_steps = max_epochs, decay_rate = 0.03)\n",
    "        momentum = 0.9 + (0.99 - 0.9) * (current_epoch / max_epochs)\n",
    "\n",
    "        # Training computation.\n",
    "        with tf.variable_scope(spec_var_scope):\n",
    "            predictions = conv_flow(tf_x_batch, num_keypoints, is_training)\n",
    "\n",
    "        loss = tf.reduce_mean(tf.square(predictions - tf_y_batch))\n",
    "\n",
    "        # Optimizer.\n",
    "        optimizer = tf.train.MomentumOptimizer(\n",
    "            learning_rate = learning_rate, \n",
    "            momentum = momentum, \n",
    "            use_nesterov = True\n",
    "        ).minimize(loss)\n",
    "    \n",
    "    # Initiate training\n",
    "    with tf.Session(graph = graph) as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.Saver()\n",
    "        train_loss_history = np.zeros(max_epochs)\n",
    "        valid_loss_history = np.zeros(max_epochs)\n",
    "        test_pred = np.zeros((x_test.shape[0],y.shape[1]))\n",
    "        \n",
    "        print(\" RESTORING SESSION FOR WEIGHTS INITIALIZATION\")\n",
    "        # Exclude output layer weights from variables we will restore\n",
    "        variables_to_restore = [v for v in tf.global_variables() if \"/out/\" not in v.op.name]\n",
    "        # Replace variables scope with that of the current model\n",
    "        loader = tf.train.Saver({v.op.name.replace(spec_var_scope, initialising_model): v for v in variables_to_restore})\n",
    "        load_path = root_location + initialising_model + \"/model.ckpt\"\n",
    "        loader.restore(session, load_path)\n",
    "        print(\" Model loaded from: \" + load_path)\n",
    "\n",
    "        print(\" TRAINING: \" + feature_name + \" on \" + str(y.shape[0]) + \" EXAMPLES \")\n",
    "        for epoch in range(max_epochs):\n",
    "            current_epoch = epoch\n",
    "            # print(\"epoch\", epoch)\n",
    "            # Train on whole randomised dataset in batches\n",
    "            \n",
    "            #No flipping yet\n",
    "            \n",
    "            shuffle = np.random.permutation(np.arange(x_train.shape[0])) #shuffle \n",
    "            X, y = x_train[shuffle], y_train[shuffle]\n",
    "            for i in range(int(X.shape[0]//batch_size)): \n",
    "                X_batch,y_batch = X[i*batch_size:(i+1)*batch_size,:],y[i*batch_size:(i+1)*batch_size]\n",
    "                session.run([optimizer], feed_dict = {\n",
    "                        tf_x_batch : X_batch, \n",
    "                        tf_y_batch : y_batch,\n",
    "                        is_training : True\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            \n",
    "            \n",
    "            # If another significant epoch ended, we log our losses.\n",
    "            if (epoch % every_epoch_to_log == 0):\n",
    "                # Get training data predictions and log training loss:\n",
    "                #training loss for the last batch\n",
    "                train_loss = loss.eval(feed_dict = {tf_x_batch:X_batch,tf_y_batch:y_batch, is_training : True})\n",
    "                train_loss_history[epoch] = train_loss\n",
    "            # Get validation data loss:\n",
    "                valid_loss = loss.eval(feed_dict = {tf_x_batch:x_valid,tf_y_batch:y_valid, is_training : False})\n",
    "                valid_loss_history[epoch] = valid_loss\n",
    "            \n",
    "                \n",
    "                 #training time end\n",
    "                time_stop = time.time()\n",
    "                \n",
    "                #since we have lots of epochs,and more data, and many more models, we dispaly losses for every \n",
    "                #100 epochs\n",
    "                if (epoch % 100 == 0):\n",
    "                    print(\" EPOCH %4d/%d \" % (epoch, max_epochs))\n",
    "                    print(\"Train loss: %.8f\" % (train_loss))\n",
    "                    print(\"Validation loss: %.8f\" % (valid_loss))\n",
    "                    print(\"Time: \" , time_stop - time_start)\n",
    "            \n",
    "            \n",
    "            \n",
    "        # Evaluate on test dataset.\n",
    "        test_loss =  loss.eval(feed_dict = {tf_x_batch:x_test,tf_y_batch:y_test, is_training : False})\n",
    "        \n",
    "        #Plot a graph of the train vs test loss data:\n",
    "    \n",
    "        plt.plot(train_loss_history, label=\"train\")\n",
    "        plt.plot(valid_loss_history, linewidth=3, label=\"valid\")\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.yscale(\"log\")\n",
    "        plt.show()\n",
    "        \n",
    "        print(feature_name)\n",
    "        print(\" Test score: %.3f (loss = %.8f)\" % (np.sqrt(test_loss) * 48.0, test_loss)) \n",
    "        print(\" Total time: \" ,time_stop - time_start )\n",
    "\n",
    "        # Save model weights for future use.\n",
    "        save_path = saver.save(session, model_path(feature_name))\n",
    "        print(\"Model file: \" + save_path)\n",
    "        np.savez(train_history_path(feature_name), train_loss_history = train_loss_history, valid_loss_history = valid_loss_history)\n",
    "        print(\"Train history file: \" + train_history_path(feature_name))        \n",
    "        print(\"\\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mouth_left_corner_x       2269\n",
      "mouth_left_corner_y       2269\n",
      "mouth_right_corner_x      2270\n",
      "mouth_right_corner_y      2270\n",
      "mouth_center_top_lip_x    2275\n",
      "mouth_center_top_lip_y    2275\n",
      "Image                     7049\n",
      "dtype: int64\n",
      " RESTORING SESSION FOR WEIGHTS INITIALIZATION\n",
      "INFO:tensorflow:Restoring parameters from /Users/anamika/W207_local/class/models/3con_2fc_b36_e9_aug_lrdec_mominc_dr/model.ckpt\n",
      " Model loaded from: /Users/anamika/W207_local/class/models/3con_2fc_b36_e9_aug_lrdec_mominc_dr/model.ckpt\n",
      " TRAINING: mouth_corner_top on 2260 EXAMPLES \n",
      " EPOCH    0/5 \n",
      "Train loss: 0.00829276\n",
      "Validation loss: 0.01423701\n",
      "Time:  41.626102924346924\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEKCAYAAADNSVhkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1071f54e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mouth_corner_top\n",
      " Test score: 3.927 (loss = 0.00669466)\n",
      " Total time:  41.626102924346924\n",
      "Model file: /Users/anamika/W207_local/class/models/ind_models/model_mouth_corner_top/model.ckpt\n",
      "Train history file: /Users/anamika/W207_local/class/models/ind_models/model_mouth_corner_top/train_history\n",
      "\n",
      "\n",
      "nose_tip_x    7049\n",
      "nose_tip_y    7049\n",
      "Image         7049\n",
      "dtype: int64\n",
      " RESTORING SESSION FOR WEIGHTS INITIALIZATION\n",
      "INFO:tensorflow:Restoring parameters from /Users/anamika/W207_local/class/models/3con_2fc_b36_e9_aug_lrdec_mominc_dr/model.ckpt\n",
      " Model loaded from: /Users/anamika/W207_local/class/models/3con_2fc_b36_e9_aug_lrdec_mominc_dr/model.ckpt\n",
      " TRAINING: nose_tip on 7049 EXAMPLES \n",
      " EPOCH    0/5 \n",
      "Train loss: 0.01205812\n",
      "Validation loss: 0.01127749\n",
      "Time:  129.74994206428528\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEKCAYAAAAyx7/DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmP8DH8Tv1+Gs1YQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12acd37b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nose_tip\n",
      " Test score: 5.037 (loss = 0.01101338)\n",
      " Total time:  129.74994206428528\n",
      "Model file: /Users/anamika/W207_local/class/models/ind_models/model_nose_tip/model.ckpt\n",
      "Train history file: /Users/anamika/W207_local/class/models/ind_models/model_nose_tip/train_history\n",
      "\n",
      "\n",
      " Total time for all models:  812.4140899181366\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for facial_model_label in facial_group_labels:\n",
    "    train_individual_model(facial_model_label)\n",
    "\n",
    "time_stop = time.time()    \n",
    "print(\" Total time for all models: \" , time_stop - start)    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plots history of learning curves for a specific model. \n",
    "def plot_learning_curves(spec_name, color):\n",
    "    \n",
    "    model_history = np.load(train_history_path(spec_name) + \".npz\")\n",
    "    train_loss = model_history[\"train_loss_history\"]\n",
    "    valid_loss = model_history[\"valid_loss_history\"]\n",
    "    epochs = train_loss.shape[0]\n",
    "    x_axis = np.arange(epochs)\n",
    "    plt.plot(x_axis[train_loss > 0], train_loss[train_loss > 0], color + \"--\", linewidth=2, label = spec_name.replace(\"_\", \" \").title())\n",
    "    plt.plot(x_axis[valid_loss > 0], valid_loss[valid_loss > 0], color + \"-\", linewidth=2)\n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mouth_corner_top\n",
      "nose_tip\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFphJREFUeJzt3X1wVfW97/H3V6ByBIJHyGmVtKI9NT4ABi3QmmJTvD4i\n1rYqYkWUtmhHa51LrdrrHSzOUGd0bq3aonjVI5UCtaWOT/eotaY+1AMUzMEHDoqYqemcO/akVyVa\nrNHf/SPbBFBgr8hybXber5kMWWuv/Vvf/BLyyW89/FaklJAkqVy7FV2AJGnXYnBIkjIxOCRJmRgc\nkqRMDA5JUiYGhyQpE4NDkpSJwSFJysTgkCRl0r/oAnamiJgCTNljjz2+ddBBBxVdTkV44403GDRo\nUNFlVAT7ood90cO+6LFq1ar/SinV7mi7qMYpR+rr69O6deuKLqMiNDc309TUVHQZFcG+6GFf9LAv\nekTEqpTSZ3e0nYeqJEmZGBySpEwMDklSJlV1clxSdm+//TZtbW1s2rSp6FIKMXToUNauXVt0GR+p\ngQMHUldXx4ABA3r1foND6uPa2toYMmQII0eOJCKKLucjt3HjRoYMGVJ0GR+ZlBLt7e20tbWx3377\n9aoND1VJfdymTZsYNmxYnwyNvigiGDZs2IcaYRockgyNPubDfr8NDklSJlUVHBExJSIWdHR0FF2K\npAwigjPPPLN7ubOzk9raWk488cRetffqq6/ys5/9rHu5ubm57LauueYaDjzwQBoaGhg3bhwLFy7s\nVQ07w4QJE2hoaOBTn/oUtbW1NDQ00NDQQGtra2E1QZUFR0rpnpTSrMGDBxddiqQMBg0axDPPPMPf\n/vY3AB566CFGjBjR6/a2Do5y3XjjjTz00EOsWLGClpYWHn74YbLMrvHOO+9k3ufmOjs7t1hevnw5\nLS0tzJ07l6lTp9LS0kJLSwsjR478UPv5sKoqOCTtuk444QTuu+8+ABYvXsy0adO6X/vrX//KySef\nzJgxY/jc5z7HmjVrALjiiiu45pprurcbNWoUra2tXHrppbz44os0NDRw8cUXA9DR0cEpp5zCgQce\nyNe//vUPDIR58+Yxf/58ampqAKipqWHGjBkAPPzww4wdO5bRo0czc+ZM3nrrLQBGjhzJJZdcwmGH\nHcadd95JU1MTl1xyCePHj+eAAw7gscceA7pC5eKLL2bcuHGMGTOGm266CegaDU2cOJGTTjqJgw8+\nuOz+uuOOOxg9ejSjRo3iBz/4AdAVPHvuuScXXnghhxxyCEcffTTt7e1lt1kug0PSFiK2/bFgQc92\nCxZsf9usTj/9dJYsWcKmTZtYs2YNEyZM6H5tzpw5jB07ljVr1jBv3jzOOuus7bZ11VVX8elPf5qW\nlhauvvpqAJ566imuvfZannvuOTZs2MATTzyxxXtef/11Nm7cyP777/++9jZt2sTZZ5/N0qVLefrp\np+ns7GT+/Pndrw8bNozVq1dz+umnA12/wFesWMG1117LD3/4QwBuueUWhg4dysqVK1m5ciU333wz\nL730EgCrV6/mJz/5Cc8//3xZfdXW1sbll1/OI488wlNPPcUTTzzBvffeC8Brr71GY2Mjzz77LJ//\n/Oe58sory2ozC4NDUkUYM2YMra2tLF68mBNOOGGL1x5//HGmT58OwKRJk2hvb+f111/P1P748eOp\nq6tjt912y3yeYN26dey3334ccMABAMyYMYNHH320+/WpU6dusf1Xv/pVAA4//PDu/Tz44IMsXLiQ\nhoYGJkyYQHt7Oy+88EJ3bVnuqVi+fDmTJk1i+PDhDBgwgDPOOKO7nv79+3PqqacCcOaZZ/L444+X\n3W65vAFQ0hbKPaQ/a1bXx8500kkn8b3vfY/m5uayDrH079+fd999t3t5e/cm7L777t2f9+vX733n\nE2pqahg8eDAbNmz4wFHH9mw9Lft7+9p8Pyklrr/+eo499tgttm1ubs51Wvc8LrV2xCGpYsycOZM5\nc+YwevToLdZPnDiRRYsWAV2/aIcPH05NTQ0jR45k9erVQNfhnvcO/QwZMoSNGzdm3v9ll13G+eef\n3z2a6ejoYOHChdTX19Pa2sr69esB+PnPf84Xv/jFTG0fe+yxzJ8/n7fffhuA559/njfeeCNzjdB1\ntdUjjzxCe3s7nZ2dLFmypLuezs5Oli1bBsAvfvELvvCFL/RqH9vjiENSxairq+PCCy983/orrriC\nmTNnMmbMGPbYYw9uv/12AL72ta+xcOFCDjnkECZMmNB9KGnYsGE0NjYyatQojj/+eCZPnlzW/r/9\n7W/T0dHBuHHjGDBgAAMGDGD27NkMHDiQ2267jVNPPZXOzk7GjRvHeeedl+lr++Y3v0lrayuHHXYY\nKSVqa2u56667MrXxnrq6Oq688kqamppIKTFlyhQmT55MZ2cnQ4cO5bHHHmPOnDnsvffeLF26tFf7\n2B4f5FTlfEhND/uix+Z9sXbtWvryEzOraa6qzs5Ohg8fzquvvrrDbT/o++6DnCRJuTA4JKlK9O/f\nv6zRxodlcEiSMqmq4HCuKknKX1UFh3NVSVL+qio4JEn5MzgkFS4imD17dvfyNddcwxVXXLHT99Pe\n3t49NfknPvEJRowYQWNjIw0NDfz973/niCOO2On7rEbeACipcLvvvjvLli3jsssuY/jw4bntZ9iw\nYbS0tABdNxUOHjyYc889t/s+jj/84Q+57buaOOKQVLj+/fsza9YsfvzjH7/vtdbWViZNmsSYMWM4\n6qij+NOf/gTAnXfeyahRozj00EM58sgjgW1PXV6u986PNjc3c+SRRzJ58mTq6+s577zztpgTq69z\nxCFpC/HDbU+Kd9OJNzHr8K6ZDResWsC59567zW3TnGyzUpx//vmMGTOG73//+1us/853vsOMGTOY\nMWMGt956KxdeeCF33XUXc+fO5YEHHmDEiBHd9y5sPnX5W2+9RWNjI8ccc0ymmWffs2LFCp577jn2\n3XdfjjvuOJYtW8Ypp5ySuZ1q5IhDUkWoqanhrLPO4rrrrtti/ZNPPskZZ5wBwPTp07unCW9sbOTs\ns8/m5ptv7n7y3vamLs9q/Pjx7L///vTr149p06blMj35rsoRh6QtlDtSmHX4rO7Rx85y0UUXcdhh\nh3HOOefscNsbb7yR5cuXc99993H44YezatWqbU5d3htbT0eex/TkuypHHJIqxl577cVpp53GLbfc\n0r3uiCOOYMmSJQAsWrSIiRMnAvDiiy8yYcIE5s6dS21tLS+//PJOnbp8xYoVvPTSS7z77rssXbo0\nl+nJd1WOOCRVlNmzZ3PDDTd0L19//fWcc845XH311dTW1nLbbbcBcPHFF/PCCy+QUuKoo47i0EMP\n7X6K4M6YunzcuHFccMEFrF+/ni996Ut85Stf2SlfXzUwOCQVbvNpgj7+8Y/z5ptvdi/vu+++/O53\nv3vfe957WNHmIoJ58+Yxb968He7zvftENn/g0+Z11NTUdD/HW1vyUJUkKRNHHJK0laamJh/6tR2O\nOCRRjU8C1bZ92O+3wSH1cQMHDqS9vd3w6CNSSrS3tzNw4MBet+GhKqmPq6uro62tjb/85S9Fl1KI\nTZs2fahforuigQMHUldX1+v3V1VwRMQUYMo+++xTdCnSLmPAgAG9mpKjWjQ3NzN27Niiy9ilVNWh\nKh/kJEn5q6rgkCTlz+CQJGVicEiSMjE4JEmZGBySpEwMDklSJgaHJCkTg0OSlInBIUnKxOCQJGVi\ncEiSMjE4JEmZGBySpEwMDklSJgaHJCkTg0OSlInBIUnKxOCQJGVicEiSMjE4JEmZGBySpEwMDklS\nJgaHJCkTg0OSlEn/ogvYkYg4GZgM1AC3pJQeLLgkSerTch1xRMStEfFKRDyz1frjImJdRKyPiEu3\n10ZK6a6U0reA84CpedYrSdqxvEcc/wLcACx8b0VE9AN+ChwNtAErI+JuoB/wo63ePzOl9Erp88tL\n75MkFSjX4EgpPRoRI7daPR5Yn1LaABARS4Avp5R+BJy4dRsREcBVwP9JKa3Os15J0o4VcY5jBPDy\nZsttwITtbP8d4L8BQyPin1NKN37QRhExC5gFUFtbS3Nz886pdhfX0dFhX5TYFz3six72RXYVf3I8\npXQdcF0Z2y0AFgDU19enpqamnCvbNTQ3N2NfdLEvetgXPeyL7Iq4HPfPwCc3W64rrZMk7QKKCI6V\nwGciYr+I+BhwOnB3AXVIknoh78txFwNPAvUR0RYR30gpdQIXAA8Aa4FfppSe3Un7mxIRCzo6OnZG\nc5KkD5D3VVXTtrH+fuD+HPZ3D3BPfX39t3Z225KkLk45IknKxOCQJGVicEiSMqmq4PDkuCTlr6qC\nI6V0T0pp1uDBg4suRZKqVlUFhyQpfwaHJCkTg0OSlInBIUnKpKqCw6uqJCl/VRUcXlUlSfmrquCQ\nJOXP4JAkZWJwSJIyMTgkSZlUVXB4VZUk5a+qgsOrqiQpf1UVHJKk/BkckqRMDA5JUiYGhyQpE4ND\nkpSJwSFJyqSqgsP7OCQpf1UVHN7HIUn5q6rgkCTlz+CQJGVSVnBExHcjoia63BIRqyPimLyLkyRV\nnnJHHDNTSq8DxwD/CEwHrsqtKklSxSo3OKL07wnAz1NKz262TpLUh5QbHKsi4kG6guOBiBgCvJtf\nWZKkStW/zO2+ATQAG1JKb0bEXsA5+ZUlSapU5Y44Pg+sSym9GhFnApcDr+VXliSpUpUbHPOBNyPi\nUGA28CKwMLeqesk7xyUpf+UGR2dKKQFfBm5IKf0UGJJfWb3jneOSlL9yz3FsjIjL6LoMd2JE7AYM\nyK8sSVKlKnfEMRV4i677Of4vUAdcnVtVkqSKVVZwlMJiETA0Ik4ENqWUKu4chyQpf+VOOXIasAI4\nFTgNWB4Rp+RZmCSpMpV7juN/AONSSq8AREQt8FvgV3kVJkmqTOWe49jtvdAoac/wXklSFSl3xPGv\nEfEAsLi0PBW4P5+SJEmVrKzgSCldHBFfAxpLqxaklH6TX1mSpEpV7oiDlNKvgV/nWIskaRew3eCI\niI1A+qCXgJRSqsmlKklSxdpucKSUKm5ake2JiCnAlH322afoUiSpalXVlVHOVSVJ+auq4JAk5c/g\nkCRlYnBIkjIxOCRJmRgckqRMDA5JUiYGhyQpE4NDkpSJwSFJysTgkCRlYnBIkjIxOCRJmRgckqRM\nDA5JUiYGhyQpk6oKjoiYEhELOjo6ii5FkqpWVQWHD3KSpPxVVXBIkvJncEiSMjE4JEmZGBySpEwM\nDklSJgaHJCkTg0OSlInBIUnKxOCQJGVicEiSMjE4JEmZGBySpEwMDklSJgaHJCkTg0OSlInBIUnK\nxOCQJGVicEiSMjE4JEmZGBySpEwMDklSJgaHJCkTg0OSlInBIUnKpOKDIyIOiogbI+JXEfHtouuR\npL4u1+CIiFsj4pWIeGar9cdFxLqIWB8Rl26vjZTS2pTSecBpQGOe9UqSdizvEce/AMdtviIi+gE/\nBY4HDgamRcTBETE6Iu7d6uOfSu85CbgPuD/neiVJO9A/z8ZTSo9GxMitVo8H1qeUNgBExBLgyyml\nHwEnbqOdu4G7I+I+4Bf5VSxJ2pFcg2MbRgAvb7bcBkzY1sYR0QR8Fdid7Yw4ImIWMAugtraW5ubm\nnVDqrq+jo8O+KLEvetgXPeyL7IoIjkxSSs1AcxnbLQAWANTX16empqZc69pVNDc3Y190sS962Bc9\n7Ivsiriq6s/AJzdbriutkyTtAooIjpXAZyJiv4j4GHA6cHcBdUiSeiHvy3EXA08C9RHRFhHfSCl1\nAhcADwBrgV+mlJ7dSfubEhELOjo6dkZzkqQPkPdVVdO2sf5+cri0NqV0D3BPfX39t3Z225KkLhV/\n57gkqbIYHJKkTAwOSVImVRUcnhyXpPxVVXCklO5JKc0aPHhw0aVIUtWqquCQJOXP4JAkZWJwSJIy\nMTgkSZlUVXB4VZUk5a+qgsOrqiQpf1UVHJKk/BkckqRMDA5JUiYGhyQpk6oKDq+qkqT8VVVweFWV\nJOWvqoJDkpQ/g0OSlInBIUnKxOCQJGVicEiSMjE4JEmZVFVweB+HJOWvqoLD+zgkKX9VFRySpPwZ\nHJKkTAwOSVImBockKRODQ5KUicEhScrE4JAkZWJwSJIyqarg8M5xScpfVQWHd45LUv6qKjgkSfkz\nOCRJmRgckqRMDA5JUiYGhyQpE4NDkpSJwSFJysTgkCRlYnBIkjIxOCRJmfQvuoCdKSKmAFOATRHx\nbNH1VIjhwH8VXUSFsC962Bc97Ise9eVsFCmlvAv5yEXEH1NKny26jkpgX/SwL3rYFz3six7l9oWH\nqiRJmRgckqRMqjU4FhRdQAWxL3rYFz3six72RY+y+qIqz3FIkvJTrSMOSVJOqio4IuK4iFgXEesj\n4tKi6ylSRNwaEa9ExDNF11KkiPhkRDwSEc9FxLMR8d2iaypKRAyMiBUR8e+lvvhh0TUVLSL6RcRT\nEXFv0bUUKSJaI+LpiGiJiD/ucPtqOVQVEf2A54GjgTZgJTAtpfRcoYUVJCKOBDqAhSmlUUXXU5SI\n2BvYO6W0OiKGAKuAk/viz0VEBDAopdQREQOAx4HvppT+reDSChMR/x34LFCTUjqx6HqKEhGtwGdT\nSmXdz1JNI47xwPqU0oaU0t+BJcCXC66pMCmlR4G/Fl1H0VJK/5lSWl36fCOwFhhRbFXFSF06SosD\nSh/V8ZdjL0REHTAZ+N9F17KrqabgGAG8vNlyG330F4Q+WESMBMYCy4utpDilQzMtwCvAQymlPtsX\nwLXA94F3iy6kAiTgtxGxKiJm7WjjagoOaZsiYjDwa+CilNLrRddTlJTSOymlBqAOGB8RffIwZkSc\nCLySUlpVdC0V4guln4vjgfNLh7q3qZqC48/AJzdbriutUx9XOp7/a2BRSmlZ0fVUgpTSq8AjwHFF\n11KQRuCk0rH9JcCkiLij2JKKk1L6c+nfV4Df0HXof5uqKThWAp+JiP0i4mPA6cDdBdekgpVOCN8C\nrE0p/a+i6ylSRNRGxJ6lz/+BrgtJ/qPYqoqRUrospVSXUhpJ1++K36WUziy4rEJExKDShSNExCDg\nGGC7V2NWTXCklDqBC4AH6DoB+suUUp+dITciFgNPAvUR0RYR3yi6poI0AtPp+ouypfRxQtFFFWRv\n4JGIWEPXH1oPpZT69GWoAuDjwOMR8e/ACuC+lNK/bu8NVXM5riTpo1E1Iw5J0kfD4JAkZWJwSJIy\nMTgkSZkYHJKkTAwOqcJERFNfn61Vlc3gkCRlYnBIvRQRZ5aeb9ESETeVJhDsiIgfl5538XBE1Ja2\nbYiIf4uINRHxm4j4x9L6f46I35aekbE6Ij5dan5wRPwqIv4jIhaV7oCXKoLBIfVCRBwETAUaS5PD\nvQN8HRgE/DGldAjwe2BO6S0LgUtSSmOApzdbvwj4aUrpUOAI4D9L68cCFwEHA/vTdQe8VBH6F12A\ntIs6CjgcWFkaDPwDXVOVvwssLW1zB7AsIoYCe6aUfl9afztwZ2l+oBEppd8ApJQ2AZTaW5FSaist\ntwAj6XrwklQ4g0PqnQBuTyldtsXKiP+51Xa9ndPnrc0+fwf/r6qCeKhK6p2HgVMi4p8AImKviNiX\nrv9Tp5S2OQN4PKX0GvD/ImJiaf104PelJxK2RcTJpTZ2j4g9PtKvQuoF/4qReiGl9FxEXA48GBG7\nAW8D5wNv0PWApMvpOnQ1tfSWGcCNpWDYAJxTWj8duCki5pbaOPUj/DKkXnF2XGknioiOlNLgouuQ\n8uShKklSJo44JEmZOOKQJGVicEiSMjE4JEmZGBySpEwMDklSJgaHJCmT/w/tutIt7wtCjQAAAABJ\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c3885f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_model_epochs = 0\n",
    "colors = [\"b\", \"g\", \"r\", \"c\", \"m\", \"y\", \"k\", \"w\"]\n",
    "for facial_model_label in facial_group_labels:\n",
    "    ind_epochs = plot_learning_curves(facial_model_label['name'], colors[facial_group_labels.index(facial_model_label) % len(colors)])\n",
    "    print(facial_model_label['name'])\n",
    "    if ind_epochs > max_model_epochs:\n",
    "          max_model_epochs = ind_epochs\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.ylim(0.0003, 0.05)\n",
    "plt.xlim(0, max_model_epochs)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
