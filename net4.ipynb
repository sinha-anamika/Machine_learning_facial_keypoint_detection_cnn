{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GRID K520 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN not available)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from pandas.io.parsers import read_csv\n",
    "from sklearn.utils import shuffle\n",
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "import theano\n",
    "from nolearn.lasagne import BatchIterator\n",
    "\n",
    "FTRAIN = '~/data/kaggle-facial-keypoint-detection/training.csv'\n",
    "FTEST = '~/data/kaggle-facial-keypoint-detection/test.csv'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(test=False, cols=None):\n",
    "    \"\"\"Loads data from FTEST if *test* is True, otherwise from FTRAIN.\n",
    "    Pass a list of *cols* if you're only interested in a subset of the\n",
    "    target columns.\n",
    "    \"\"\"\n",
    "    fname = FTEST if test else FTRAIN\n",
    "    df = read_csv(os.path.expanduser(fname))  # load pandas dataframe\n",
    "\n",
    "    # The Image column has pixel values separated by space; convert\n",
    "    # the values to numpy arrays:\n",
    "    df['Image'] = df['Image'].apply(lambda im: np.fromstring(im, sep=' '))\n",
    "\n",
    "    if cols:  # get a subset of columns\n",
    "        df = df[list(cols) + ['Image']]\n",
    "\n",
    "    print(df.count())  # prints the number of values for each column\n",
    "    df = df.dropna()  # drop all rows that have missing values in them\n",
    "\n",
    "    X = np.vstack(df['Image'].values) / 255.  # scale pixel values to [0, 1]\n",
    "    X = X.astype(np.float32)\n",
    "\n",
    "    if not test:  # only FTRAIN has any target columns\n",
    "        y = df[df.columns[:-1]].values\n",
    "        y = (y - 48) / 48  # scale target coordinates to [-1, 1]\n",
    "        X, y = shuffle(X, y, random_state=42)  # shuffle train data\n",
    "        y = y.astype(np.float32)\n",
    "    else:\n",
    "        y = None\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def load2d(test=False, cols=None):\n",
    "    X, y = load(test=test)\n",
    "    X = X.reshape(-1, 1, 96, 96)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "class FlipBatchIterator(BatchIterator):\n",
    "    flip_indices = [\n",
    "        (0, 2), (1, 3),\n",
    "        (4, 8), (5, 9), (6, 10), (7, 11),\n",
    "        (12, 16), (13, 17), (14, 18), (15, 19),\n",
    "        (22, 24), (23, 25),\n",
    "        ]\n",
    "\n",
    "    def transform(self, Xb, yb):\n",
    "        Xb, yb = super(FlipBatchIterator, self).transform(Xb, yb)\n",
    "\n",
    "        # Flip half of the images in this batch at random:\n",
    "        bs = Xb.shape[0]\n",
    "        indices = np.random.choice(bs, bs / 2, replace=False)\n",
    "        Xb[indices] = Xb[indices, :, :, ::-1]\n",
    "\n",
    "        if yb is not None:\n",
    "            # Horizontal flip of all x coordinates:\n",
    "            yb[indices, ::2] = yb[indices, ::2] * -1\n",
    "\n",
    "            # Swap places, e.g. left_eye_center_x -> right_eye_center_x\n",
    "            for a, b in self.flip_indices:\n",
    "                yb[indices, a], yb[indices, b] = (\n",
    "                    yb[indices, b], yb[indices, a])\n",
    "\n",
    "        return Xb, yb\n",
    "\n",
    "def float32(k):\n",
    "    return np.cast['float32'](k)\n",
    "\n",
    "class AdjustVariable(object):\n",
    "    def __init__(self, name, start=0.03, stop=0.001):\n",
    "        self.name = name\n",
    "        self.start, self.stop = start, stop\n",
    "        self.ls = None\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        if self.ls is None:\n",
    "            self.ls = np.linspace(self.start, self.stop, nn.max_epochs)\n",
    "\n",
    "        epoch = train_history[-1]['epoch']\n",
    "        new_value = float32(self.ls[epoch - 1])\n",
    "        getattr(nn, self.name).set_value(new_value)\n",
    "\n",
    "\n",
    "X, y = load()\n",
    "print(\"X.shape == {}; X.min == {:.3f}; X.max == {:.3f}\".format(\n",
    "    X.shape, X.min(), X.max()))\n",
    "print(\"y.shape == {}; y.min == {:.3f}; y.max == {:.3f}\".format(\n",
    "    y.shape, y.min(), y.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_eye_center_x            7039\n",
      "left_eye_center_y            7039\n",
      "right_eye_center_x           7036\n",
      "right_eye_center_y           7036\n",
      "left_eye_inner_corner_x      2271\n",
      "left_eye_inner_corner_y      2271\n",
      "left_eye_outer_corner_x      2267\n",
      "left_eye_outer_corner_y      2267\n",
      "right_eye_inner_corner_x     2268\n",
      "right_eye_inner_corner_y     2268\n",
      "right_eye_outer_corner_x     2268\n",
      "right_eye_outer_corner_y     2268\n",
      "left_eyebrow_inner_end_x     2270\n",
      "left_eyebrow_inner_end_y     2270\n",
      "left_eyebrow_outer_end_x     2225\n",
      "left_eyebrow_outer_end_y     2225\n",
      "right_eyebrow_inner_end_x    2270\n",
      "right_eyebrow_inner_end_y    2270\n",
      "right_eyebrow_outer_end_x    2236\n",
      "right_eyebrow_outer_end_y    2236\n",
      "nose_tip_x                   7049\n",
      "nose_tip_y                   7049\n",
      "mouth_left_corner_x          2269\n",
      "mouth_left_corner_y          2269\n",
      "mouth_right_corner_x         2270\n",
      "mouth_right_corner_y         2270\n",
      "mouth_center_top_lip_x       2275\n",
      "mouth_center_top_lip_y       2275\n",
      "mouth_center_bottom_lip_x    7016\n",
      "mouth_center_bottom_lip_y    7016\n",
      "Image                        7049\n",
      "dtype: int64\n",
      "# Neural Network with 8051502 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name     size\n",
      "---  -------  ---------\n",
      "  0  input    1x96x96\n",
      "  1  conv1    32x94x94\n",
      "  2  pool1    32x47x47\n",
      "  3  conv2    64x46x46\n",
      "  4  pool2    64x23x23\n",
      "  5  conv3    128x22x22\n",
      "  6  pool3    128x11x11\n",
      "  7  hidden4  500\n",
      "  8  hidden5  500\n",
      "  9  output   30\n",
      "\n",
      "  epoch    trn loss    val loss    trn/val  dur\n",
      "-------  ----------  ----------  ---------  -----\n",
      "      1     \u001b[36m0.06583\u001b[0m     \u001b[32m0.01022\u001b[0m    6.44119  8.38s\n",
      "      2     \u001b[36m0.00874\u001b[0m     \u001b[32m0.00657\u001b[0m    1.32866  8.38s\n",
      "      3     \u001b[36m0.00640\u001b[0m     \u001b[32m0.00561\u001b[0m    1.14014  8.38s\n",
      "      4     \u001b[36m0.00563\u001b[0m     \u001b[32m0.00511\u001b[0m    1.10323  8.38s\n",
      "      5     \u001b[36m0.00522\u001b[0m     \u001b[32m0.00480\u001b[0m    1.08834  8.38s\n",
      "      6     \u001b[36m0.00497\u001b[0m     \u001b[32m0.00461\u001b[0m    1.07854  8.39s\n",
      "      7     \u001b[36m0.00481\u001b[0m     \u001b[32m0.00449\u001b[0m    1.07189  8.39s\n",
      "      8     \u001b[36m0.00470\u001b[0m     \u001b[32m0.00441\u001b[0m    1.06712  8.38s\n",
      "      9     \u001b[36m0.00463\u001b[0m     \u001b[32m0.00436\u001b[0m    1.06315  8.38s\n",
      "     10     \u001b[36m0.00458\u001b[0m     \u001b[32m0.00432\u001b[0m    1.06013  8.39s\n",
      "     11     \u001b[36m0.00455\u001b[0m     \u001b[32m0.00430\u001b[0m    1.05791  8.39s\n",
      "     12     \u001b[36m0.00452\u001b[0m     \u001b[32m0.00428\u001b[0m    1.05631  8.39s\n",
      "     13     \u001b[36m0.00451\u001b[0m     \u001b[32m0.00427\u001b[0m    1.05507  8.39s\n",
      "     14     \u001b[36m0.00449\u001b[0m     \u001b[32m0.00426\u001b[0m    1.05417  8.38s\n",
      "     15     \u001b[36m0.00448\u001b[0m     \u001b[32m0.00425\u001b[0m    1.05338  8.39s\n",
      "     16     \u001b[36m0.00447\u001b[0m     \u001b[32m0.00425\u001b[0m    1.05273  8.39s\n",
      "     17     \u001b[36m0.00446\u001b[0m     \u001b[32m0.00424\u001b[0m    1.05215  8.38s\n",
      "     18     \u001b[36m0.00445\u001b[0m     \u001b[32m0.00423\u001b[0m    1.05173  8.38s\n",
      "     19     \u001b[36m0.00444\u001b[0m     \u001b[32m0.00423\u001b[0m    1.05156  8.39s\n",
      "     20     \u001b[36m0.00443\u001b[0m     \u001b[32m0.00422\u001b[0m    1.05138  8.39s\n",
      "     21     \u001b[36m0.00443\u001b[0m     \u001b[32m0.00421\u001b[0m    1.05120  8.39s\n",
      "     22     \u001b[36m0.00442\u001b[0m     \u001b[32m0.00420\u001b[0m    1.05107  8.38s\n",
      "     23     \u001b[36m0.00441\u001b[0m     \u001b[32m0.00420\u001b[0m    1.05089  8.38s\n",
      "     24     \u001b[36m0.00440\u001b[0m     \u001b[32m0.00419\u001b[0m    1.05078  8.39s\n",
      "     25     \u001b[36m0.00439\u001b[0m     \u001b[32m0.00418\u001b[0m    1.05072  8.39s\n",
      "     26     \u001b[36m0.00439\u001b[0m     \u001b[32m0.00417\u001b[0m    1.05070  8.39s\n",
      "     27     \u001b[36m0.00438\u001b[0m     \u001b[32m0.00417\u001b[0m    1.05065  8.39s\n",
      "     28     \u001b[36m0.00437\u001b[0m     \u001b[32m0.00416\u001b[0m    1.05060  8.38s\n",
      "     29     \u001b[36m0.00436\u001b[0m     \u001b[32m0.00415\u001b[0m    1.05051  8.38s\n",
      "     30     \u001b[36m0.00435\u001b[0m     \u001b[32m0.00414\u001b[0m    1.05051  8.39s\n",
      "     31     \u001b[36m0.00434\u001b[0m     \u001b[32m0.00413\u001b[0m    1.05041  8.39s\n",
      "     32     \u001b[36m0.00433\u001b[0m     \u001b[32m0.00412\u001b[0m    1.05026  8.39s\n",
      "     33     \u001b[36m0.00432\u001b[0m     \u001b[32m0.00412\u001b[0m    1.05019  8.38s\n",
      "     34     \u001b[36m0.00431\u001b[0m     \u001b[32m0.00411\u001b[0m    1.04995  8.38s\n",
      "     35     \u001b[36m0.00430\u001b[0m     \u001b[32m0.00410\u001b[0m    1.04982  8.38s\n",
      "     36     \u001b[36m0.00429\u001b[0m     \u001b[32m0.00409\u001b[0m    1.04968  8.38s\n",
      "     37     \u001b[36m0.00428\u001b[0m     \u001b[32m0.00408\u001b[0m    1.04957  8.39s\n",
      "     38     \u001b[36m0.00427\u001b[0m     \u001b[32m0.00407\u001b[0m    1.04946  8.38s\n",
      "     39     \u001b[36m0.00426\u001b[0m     \u001b[32m0.00406\u001b[0m    1.04941  8.39s\n",
      "     40     \u001b[36m0.00425\u001b[0m     \u001b[32m0.00405\u001b[0m    1.04937  8.39s\n",
      "     41     \u001b[36m0.00424\u001b[0m     \u001b[32m0.00404\u001b[0m    1.04931  8.39s\n",
      "     42     \u001b[36m0.00423\u001b[0m     \u001b[32m0.00403\u001b[0m    1.04930  8.39s\n",
      "     43     \u001b[36m0.00422\u001b[0m     \u001b[32m0.00402\u001b[0m    1.04926  8.39s\n",
      "     44     \u001b[36m0.00420\u001b[0m     \u001b[32m0.00401\u001b[0m    1.04926  8.39s\n",
      "     45     \u001b[36m0.00419\u001b[0m     \u001b[32m0.00400\u001b[0m    1.04899  8.38s\n",
      "     46     \u001b[36m0.00418\u001b[0m     \u001b[32m0.00398\u001b[0m    1.04893  8.38s\n",
      "     47     \u001b[36m0.00417\u001b[0m     \u001b[32m0.00397\u001b[0m    1.04890  8.38s\n",
      "     48     \u001b[36m0.00415\u001b[0m     \u001b[32m0.00396\u001b[0m    1.04889  8.39s\n",
      "     49     \u001b[36m0.00414\u001b[0m     \u001b[32m0.00395\u001b[0m    1.04880  8.38s\n",
      "     50     \u001b[36m0.00413\u001b[0m     \u001b[32m0.00394\u001b[0m    1.04836  8.39s\n",
      "     51     \u001b[36m0.00411\u001b[0m     \u001b[32m0.00392\u001b[0m    1.04812  8.39s\n",
      "     52     \u001b[36m0.00410\u001b[0m     \u001b[32m0.00391\u001b[0m    1.04797  8.39s\n",
      "     53     \u001b[36m0.00408\u001b[0m     \u001b[32m0.00390\u001b[0m    1.04779  8.39s\n",
      "     54     \u001b[36m0.00407\u001b[0m     \u001b[32m0.00389\u001b[0m    1.04755  8.39s\n",
      "     55     \u001b[36m0.00406\u001b[0m     \u001b[32m0.00387\u001b[0m    1.04728  8.39s\n",
      "     56     \u001b[36m0.00404\u001b[0m     \u001b[32m0.00386\u001b[0m    1.04692  8.38s\n",
      "     57     \u001b[36m0.00403\u001b[0m     \u001b[32m0.00385\u001b[0m    1.04650  8.38s\n",
      "     58     \u001b[36m0.00401\u001b[0m     \u001b[32m0.00384\u001b[0m    1.04605  8.39s\n",
      "     59     \u001b[36m0.00400\u001b[0m     \u001b[32m0.00382\u001b[0m    1.04562  8.39s\n",
      "     60     \u001b[36m0.00398\u001b[0m     \u001b[32m0.00381\u001b[0m    1.04520  8.39s\n",
      "     61     \u001b[36m0.00397\u001b[0m     \u001b[32m0.00380\u001b[0m    1.04466  8.38s\n",
      "     62     \u001b[36m0.00395\u001b[0m     \u001b[32m0.00379\u001b[0m    1.04411  8.39s\n",
      "     63     \u001b[36m0.00394\u001b[0m     \u001b[32m0.00377\u001b[0m    1.04364  8.38s\n",
      "     64     \u001b[36m0.00392\u001b[0m     \u001b[32m0.00376\u001b[0m    1.04328  8.39s\n",
      "     65     \u001b[36m0.00391\u001b[0m     \u001b[32m0.00375\u001b[0m    1.04285  8.39s\n",
      "     66     \u001b[36m0.00389\u001b[0m     \u001b[32m0.00373\u001b[0m    1.04248  8.39s\n",
      "     67     \u001b[36m0.00387\u001b[0m     \u001b[32m0.00372\u001b[0m    1.04207  8.39s\n",
      "     68     \u001b[36m0.00386\u001b[0m     \u001b[32m0.00370\u001b[0m    1.04148  8.39s\n",
      "     69     \u001b[36m0.00384\u001b[0m     \u001b[32m0.00369\u001b[0m    1.04102  8.39s\n",
      "     70     \u001b[36m0.00382\u001b[0m     \u001b[32m0.00368\u001b[0m    1.04048  8.39s\n",
      "     71     \u001b[36m0.00381\u001b[0m     \u001b[32m0.00366\u001b[0m    1.03989  8.39s\n",
      "     72     \u001b[36m0.00379\u001b[0m     \u001b[32m0.00365\u001b[0m    1.03930  8.39s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "net4 = NeuralNet(\n",
    "        layers=[\n",
    "        ('input', layers.InputLayer),\n",
    "        ('conv1', layers.Conv2DLayer),\n",
    "        ('pool1', layers.MaxPool2DLayer),\n",
    "        ('conv2', layers.Conv2DLayer),\n",
    "        ('pool2', layers.MaxPool2DLayer),\n",
    "        ('conv3', layers.Conv2DLayer),\n",
    "        ('pool3', layers.MaxPool2DLayer),\n",
    "        ('hidden4', layers.DenseLayer),\n",
    "        ('hidden5', layers.DenseLayer),\n",
    "        ('output', layers.DenseLayer),\n",
    "        ],\n",
    "    input_shape=(None, 1, 96, 96),\n",
    "    conv1_num_filters=32, conv1_filter_size=(3, 3), pool1_pool_size=(2, 2),\n",
    "    conv2_num_filters=64, conv2_filter_size=(2, 2), pool2_pool_size=(2, 2),\n",
    "    conv3_num_filters=128, conv3_filter_size=(2, 2), pool3_pool_size=(2, 2),\n",
    "    hidden4_num_units=500, hidden5_num_units=500,\n",
    "    output_num_units=30, output_nonlinearity=None,\n",
    "\n",
    "    update_learning_rate=theano.shared(float32(0.03)),\n",
    "    update_momentum=theano.shared(float32(0.9)),\n",
    "    regression=True,\n",
    "    # batch_iterator_train=FlipBatchIterator(batch_size=128),\n",
    "    on_epoch_finished=[\n",
    "        AdjustVariable('update_learning_rate', start=0.03, stop=0.0001),\n",
    "        AdjustVariable('update_momentum', start=0.9, stop=0.999),\n",
    "        ],\n",
    "    max_epochs=3000,\n",
    "    verbose=1,\n",
    "    )\n",
    "\n",
    "\n",
    "X, y = load2d()  # load 2-d data\n",
    "net4.fit(X, y)\n",
    "\n",
    "import cPickle as pickle\n",
    "with open('net4.pickle', 'wb') as f:\n",
    "    pickle.dump(net4, f, -1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
